{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMrg1C0/X2S4X5uxxjY5GBY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EdvanilsonBS/Desafio/blob/main/Recomenda%C3%A7ao_por_imagens_digitais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "P99eZRWTqujT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "%%writefile kaggle.json\n",
        "{\"username\":\"<your kaggle username>\",\"key\":\"<your kaggle api key>\"}"
      ],
      "metadata": {
        "id": "uXtBvwrfv3eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "!pip install -q -U kaggle\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "lZC6Lx0pv8Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide-output\n",
        "# downloading raw images from kaggle\n",
        "!kaggle datasets download -d paramaggarwal/fashion-product-images-small\n",
        "!unzip fashion-product-images-small.zip"
      ],
      "metadata": {
        "id": "8-QOE0nnwBaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from shutil import move\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.mkdir('/content/Fashion_data')\n",
        "os.chdir('/content/Fashion_data')\n",
        "\n",
        "df = pd.read_csv('/content/styles.csv', usecols=['id','masterCategory']).reset_index()\n",
        "df['id'] = df['id'].astype('str')\n",
        "\n",
        "all_images = os.listdir('/content/images/')\n",
        "co = 0\n",
        "os.mkdir('/content/Fashion_data/categories')\n",
        "for image in tqdm(all_images):\n",
        "    category = df[df['id'] == image.split('.')[0]]['masterCategory']\n",
        "    category = str(list(category)[0])\n",
        "    if not os.path.exists(os.path.join('/content/Fashion_data/categories', category)):\n",
        "        os.mkdir(os.path.join('/content/Fashion_data/categories', category))\n",
        "    path_from = os.path.join('/content/images', image)\n",
        "    path_to = os.path.join('/content/Fashion_data/categories', category, image)\n",
        "    move(path_from, path_to)\n",
        "    co += 1\n",
        "print('Moved {} images.'.format(co))"
      ],
      "metadata": {
        "id": "ARhvPD8jwCKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "metadata": {
        "id": "LhIr4F4jwP0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODULE_HANDLE = 'https://tfhub.dev/google/bit/m-r50x3/1'\n",
        "IMAGE_SIZE = (224, 224)\n",
        "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n",
        "BATCH_SIZE = 32\n",
        "N_FEATURES = 256"
      ],
      "metadata": {
        "id": "Yc69rCpAwTLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "data_dir = '/content/Fashion_data/categories'"
      ],
      "metadata": {
        "id": "lHTEnY47wXu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
        "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
        "                   interpolation=\"bilinear\")\n",
        "\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    **datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n",
        "\n",
        "do_data_augmentation = False\n",
        "if do_data_augmentation:\n",
        "  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rotation_range=40,\n",
        "      horizontal_flip=True,\n",
        "      width_shift_range=0.2, height_shift_range=0.2,\n",
        "      shear_range=0.2, zoom_range=0.2,\n",
        "      **datagen_kwargs)\n",
        "else:\n",
        "  train_datagen = valid_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)"
      ],
      "metadata": {
        "id": "haVLSi0KwcGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
        "    hub.KerasLayer(MODULE_HANDLE, trainable=False),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(N_FEATURES,\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
        "    tf.keras.layers.Dropout(rate=0.2),\n",
        "    tf.keras.layers.Dense(train_generator.num_classes,\n",
        "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
        "])\n",
        "model.build((None,)+IMAGE_SIZE+(3,))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "1I2g1b9RwcyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimiser and loss\n",
        "lr = 0.003 * BATCH_SIZE / 512\n",
        "SCHEDULE_LENGTH = 500\n",
        "SCHEDULE_BOUNDARIES = [200, 300, 400]\n",
        "\n",
        "# Decay learning rate by a factor of 10 at SCHEDULE_BOUNDARIES.\n",
        "lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=SCHEDULE_BOUNDARIES,\n",
        "                                                                   values=[lr, lr*0.1, lr*0.001, lr*0.0001])\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
        "\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "BjOd-8XJwk7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
        "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
        "hist = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5, steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=validation_steps).history"
      ],
      "metadata": {
        "id": "7-h-LZdcxKMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(hist[\"loss\"])\n",
        "plt.plot(hist[\"val_loss\"])\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy (training and validation)\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(hist[\"accuracy\"])\n",
        "plt.plot(hist[\"val_accuracy\"])"
      ],
      "metadata": {
        "id": "N4NZNssoxNig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/drive/MyDrive/ImgSim/'):\n",
        "    os.mkdir('/content/drive/MyDrive/ImgSim/')\n",
        "\n",
        "feature_extractor = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-3].output)\n",
        "feature_extractor.save('/content/drive/MyDrive/ImgSim/bit_feature_extractor', save_format='tf')\n",
        "\n",
        "saved_model_path = '/content/drive/MyDrive/ImgSim/bit_model'\n",
        "tf.saved_model.save(model, saved_model_path)"
      ],
      "metadata": {
        "id": "xEDgP7qYxXuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "id": "hTvoO_txxkhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_paths = []\n",
        "for path in Path('/content/Fashion_data/categories').rglob('*.jpg'):\n",
        "  img_paths.append(path)\n",
        "np.random.shuffle(img_paths)"
      ],
      "metadata": {
        "id": "FyxaiDbZxlpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_img(path):\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.io.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize_with_pad(img, 224, 224)\n",
        "  img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "  return img"
      ],
      "metadata": {
        "id": "tQH5yrgHxpP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide-output\n",
        "TRANSFER_LEARNING_FLAG = 1\n",
        "if TRANSFER_LEARNING_FLAG:\n",
        "  module = tf.keras.models.load_model('/content/drive/MyDrive/ImgSim/bit_feature_extractor')\n",
        "else:\n",
        "  module_handle = \"https://tfhub.dev/google/bit/s-r50x3/ilsvrc2012_classification/1\"\n",
        "  module = hub.load(module_handle)"
      ],
      "metadata": {
        "id": "ylm9K6C4xsXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgvec_path = '/content/img_vectors/'\n",
        "Path(imgvec_path).mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "sfb4cd5PyD-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for filename in tqdm(img_paths[:5000]):\n",
        "    img = load_img(str(filename))\n",
        "    features = module(img)\n",
        "    feature_set = np.squeeze(features)\n",
        "    outfile_name = os.path.basename(filename).split('.')[0] + \".npz\"\n",
        "    out_path_file = os.path.join(imgvec_path, outfile_name)\n",
        "    np.savetxt(out_path_file, feature_set, delimiter=',')"
      ],
      "metadata": {
        "id": "nm778ovFybpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "!pip install -q annoy\n",
        "import json\n",
        "from annoy import AnnoyIndex\n",
        "from scipy import spatial\n",
        "import pickle\n",
        "from IPython.display import Image as dispImage"
      ],
      "metadata": {
        "id": "0AK5_kgOyeNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = '/content/Fashion_data/categories/Accessories/1941.jpg'\n",
        "dispImage(test_img)"
      ],
      "metadata": {
        "id": "DzCHQFRyyhH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide-output\n",
        "styles = pd.read_csv('/content/styles.csv', error_bad_lines=False)\n",
        "styles['id'] = styles['id'].astype('str')\n",
        "styles.to_csv(root_path+'/styles.csv', index=False)"
      ],
      "metadata": {
        "id": "9BA_cIAvylGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def match_id(fname):\n",
        "  return styles.index[styles.id==fname].values[0]"
      ],
      "metadata": {
        "id": "rQysDKEay_yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining data structures as empty dict\n",
        "file_index_to_file_name = {}\n",
        "file_index_to_file_vector = {}\n",
        "file_index_to_product_id = {}\n",
        "\n",
        "# Configuring annoy parameters\n",
        "dims = 256\n",
        "n_nearest_neighbors = 20\n",
        "trees = 10000\n",
        "\n",
        "# Reads all file names which stores feature vectors\n",
        "allfiles = glob.glob('/content/img_vectors/*.npz')\n",
        "\n",
        "t = AnnoyIndex(dims, metric='angular')"
      ],
      "metadata": {
        "id": "rAr0kQD0zCzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for findex, fname in tqdm(enumerate(allfiles)):\n",
        "  file_vector = np.loadtxt(fname)\n",
        "  file_name = os.path.basename(fname).split('.')[0]\n",
        "  file_index_to_file_name[findex] = file_name\n",
        "  file_index_to_file_vector[findex] = file_vector\n",
        "  try:\n",
        "    file_index_to_product_id[findex] = match_id(file_name)\n",
        "  except IndexError:\n",
        "    pass\n",
        "  t.add_item(findex, file_vector)"
      ],
      "metadata": {
        "id": "Q67HoPimzH3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide-output\n",
        "t.build(trees)\n",
        "t.save('t.ann')"
      ],
      "metadata": {
        "id": "r8CzlT6xzK2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "file_path = '/content/drive/MyDrive/ImgSim/'"
      ],
      "metadata": {
        "id": "l1wjEeC6zNbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.save(file_path+'indexer.ann')\n",
        "pickle.dump(file_index_to_file_name, open(file_path+\"file_index_to_file_name.p\", \"wb\"))\n",
        "pickle.dump(file_index_to_file_vector, open(file_path+\"file_index_to_file_vector.p\", \"wb\"))\n",
        "pickle.dump(file_index_to_product_id, open(file_path+\"file_index_to_product_id.p\", \"wb\"))"
      ],
      "metadata": {
        "id": "2G4oH0S3zQAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "from PIL import Image\n",
        "import matplotlib.image as mpimg"
      ],
      "metadata": {
        "id": "6v9o47IAzTTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_addr = 'https://images-na.ssl-images-amazon.com/images/I/81%2Bd6eSA0eL._UL1500_.jpg'\n",
        "\n",
        "!wget -q -O img.jpg $img_addr\n",
        "test_img = 'img.jpg'\n",
        "topK = 4\n",
        "\n",
        "test_vec = np.squeeze(module(load_img(test_img)))\n",
        "\n",
        "basewidth = 224\n",
        "img = Image.open(test_img)\n",
        "wpercent = (basewidth/float(img.size[0]))\n",
        "hsize = int((float(img.size[1])*float(wpercent)))\n",
        "img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
        "img"
      ],
      "metadata": {
        "id": "ZQpVSBm5zWbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_dict = {}\n",
        "for path in Path('/content/Fashion_data/categories').rglob('*.jpg'):\n",
        "  path_dict[path.name] = path\n",
        "\n",
        "nns = t.get_nns_by_vector(test_vec, n=topK)\n",
        "plt.figure(figsize=(20, 10))\n",
        "for i in range(topK):\n",
        "  x = file_index_to_file_name[nns[i]]\n",
        "  x = path_dict[x+'.jpg']\n",
        "  y = file_index_to_product_id[nns[i]]\n",
        "  title = '\\n'.join([str(j) for j in list(styles.loc[y].values[-5:])])\n",
        "  plt.subplot(1, topK, i+1)\n",
        "  plt.title(title)\n",
        "  plt.imshow(mpimg.imread(x))\n",
        "  plt.axis('off')\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "C8GE9uUAzcPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "tq16ii1hzgUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hide\n",
        "root_path = '/content/drive/MyDrive/ImgSim'"
      ],
      "metadata": {
        "id": "hskCeDVczi_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "### ----utils.py---- ###\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "root_path = '/content/drive/MyDrive/ImgSim'\n",
        "\n",
        "class Encoder:\n",
        "  encoder = tf.keras.models.load_model(os.path.join(root_path, 'bit_feature_extractor'))\n",
        "\n",
        "class Indexer:\n",
        "  dims = 256\n",
        "  topK = 6\n",
        "  indexer = AnnoyIndex(dims, 'angular')\n",
        "  indexer.load(os.path.join(root_path, 'indexer.ann'))\n",
        "\n",
        "encoder = Encoder()\n",
        "indexer = Indexer()"
      ],
      "metadata": {
        "id": "h1jhDzeEzlPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "### ----app.py---- ###\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from annoy import AnnoyIndex\n",
        "import glob\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tarfile\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import time\n",
        "from utils import encoder, indexer\n",
        "\n",
        "root_path = '/content/drive/MyDrive/ImgSim'\n",
        "\n",
        "start_time = time.time()\n",
        "encoder = encoder.encoder\n",
        "print(\"---Encoder--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "topK = 6\n",
        "\n",
        "start_time = time.time()\n",
        "t = indexer.indexer\n",
        "print(\"---Indexer--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "# load the meta data\n",
        "meta_data = pd.read_csv(os.path.join(root_path, 'styles.csv'))\n",
        "\n",
        "# load the mappings\n",
        "file_index_to_file_name = pickle.load(open(os.path.join(root_path ,'file_index_to_file_name.p'), 'rb'))\n",
        "file_index_to_file_vector = pickle.load(open(os.path.join(root_path ,'file_index_to_file_vector.p'), 'rb'))\n",
        "file_index_to_product_id = pickle.load(open(os.path.join(root_path ,'file_index_to_product_id.p'), 'rb'))\n",
        "\n",
        "# load image path mapping\n",
        "path_dict = {}\n",
        "for path in Path('/content/Fashion_data/categories').rglob('*.jpg'):\n",
        "  path_dict[path.name] = path\n",
        "\n",
        "def load_img(path):\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.io.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize_with_pad(img, 224, 224)\n",
        "  img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "  return img\n",
        "\n",
        "query_path = '/content/user_query.jpg'\n",
        "\n",
        "st.title(\"Image Similarity App\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=\"jpg\")\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    image = Image.open(uploaded_file)\n",
        "    image.save(query_path)\n",
        "    st.image(image, caption='Uploaded Image.', use_column_width=True)\n",
        "    st.write(\"\")\n",
        "    st.write(\"Top similar images...\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    test_vec = np.squeeze(encoder(load_img(query_path)))\n",
        "    print(\"---Encoding--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    start_time = time.time()\n",
        "    nns = t.get_nns_by_vector(test_vec, n=topK)\n",
        "    print(\"---SimilarityIndex--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    img_files = []\n",
        "    img_captions = []\n",
        "\n",
        "    start_time = time.time()\n",
        "    for i in nns:\n",
        "      #image files\n",
        "      img_path = str(path_dict[file_index_to_file_name[i]+'.jpg'])\n",
        "      img_file = Image.open(img_path)\n",
        "      img_files.append(img_file)\n",
        "      #image captions\n",
        "      item_id = file_index_to_product_id[i]\n",
        "      img_caption = '\\n'.join([str(j) for j in list(meta_data.loc[item_id].values[-5:])])\n",
        "      img_captions.append(img_caption)\n",
        "    print(\"---Output--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    st.image(img_files, caption=img_captions, width=200)"
      ],
      "metadata": {
        "id": "y1_n2oI_zp_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q pyngrok\n",
        "! pip install -q streamlit\n",
        "! pip install -q colab-everything\n",
        "\n",
        "from colab_everything import ColabStreamlit\n",
        "ColabStreamlit('app.py')"
      ],
      "metadata": {
        "id": "9SEq1d7Zzxq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile flask_app.py\n",
        "### ----flask_app.py---- ###\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from annoy import AnnoyIndex\n",
        "import glob\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tarfile\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "import time\n",
        "from utils import encoder, indexer\n",
        "import io\n",
        "import base64\n",
        "\n",
        "from flask import Flask, request, jsonify, send_file\n",
        "\n",
        "_PPATH = '/content/drive/MyDrive/ImgSim/'\n",
        "\n",
        "start_time = time.time()\n",
        "encoder = encoder.encoder\n",
        "print(\"---Encoder--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "topK = 6\n",
        "\n",
        "start_time = time.time()\n",
        "t = indexer.indexer\n",
        "print(\"---Indexer--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "# load the meta data\n",
        "meta_data = pd.read_csv(_PPATH+'styles.csv')\n",
        "\n",
        "# load the mappings\n",
        "file_index_to_file_name = pickle.load(open(_PPATH+'file_index_to_file_name.p', 'rb'))\n",
        "file_index_to_file_vector = pickle.load(open(_PPATH+'file_index_to_file_vector.p', 'rb'))\n",
        "file_index_to_product_id = pickle.load(open(_PPATH+'file_index_to_product_id.p', 'rb'))\n",
        "\n",
        "# load image path mapping\n",
        "path_dict = {}\n",
        "for path in Path('/content/Fashion_data/categories').rglob('*.jpg'):\n",
        "  path_dict[path.name] = path\n",
        "\n",
        "def load_img(path):\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.io.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize_with_pad(img, 224, 224)\n",
        "  img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "  return img\n",
        "\n",
        "query_path = '/content/user_query.jpg'\n",
        "\n",
        "def get_encoded_img(img):\n",
        "    img_byte_arr = io.BytesIO()\n",
        "    img.save(img_byte_arr, format='PNG')\n",
        "    my_encoded_img = base64.encodebytes(img_byte_arr.getvalue()).decode('ascii')\n",
        "    return my_encoded_img\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/fashion\", methods=[\"POST\"])\n",
        "def home():\n",
        "    file = request.files['image']\n",
        "    # Read the image via file.stream\n",
        "    img = Image.open(file.stream)\n",
        "    img.save(query_path)\n",
        "\n",
        "    start_time = time.time()\n",
        "    test_vec = np.squeeze(encoder(load_img(query_path)))\n",
        "    print(\"---Encoding--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    start_time = time.time()\n",
        "    nns = t.get_nns_by_vector(test_vec, n=topK)\n",
        "    print(\"---SimilarityIndex--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    img_files = {}\n",
        "    img_captions = {}\n",
        "\n",
        "    start_time = time.time()\n",
        "    for count, i in enumerate(nns):\n",
        "      #image files\n",
        "      img_path = str(path_dict[file_index_to_file_name[i]+'.jpg'])\n",
        "      img_file = Image.open(img_path)\n",
        "      img_files[count] = get_encoded_img(img_file)\n",
        "      #image captions\n",
        "      item_id = file_index_to_product_id[i]\n",
        "      img_caption = '\\n'.join([str(j) for j in list(meta_data.loc[item_id].values[-5:])])\n",
        "      img_captions[count] = img_caption\n",
        "    print(\"---Output--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "    return jsonify(img_files)\n",
        "\n",
        "app.run(debug=True)"
      ],
      "metadata": {
        "id": "5VaQgTsHz0a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup python3 -u flask_app.py &"
      ],
      "metadata": {
        "id": "Yn8t9TPEz6km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64\n",
        "import requests\n",
        "\n",
        "!wget -O 'img.jpg' -q 'https://images-na.ssl-images-amazon.com/images/I/61utX8kBDlL._UL1100_.jpg'\n",
        "\n",
        "url = 'http://localhost:5000/fashion'\n",
        "my_img = {'image': open('img.jpg', 'rb')}\n",
        "r = requests.post(url, files=my_img)\n",
        "\n",
        "imgs = []\n",
        "for i in range(6):\n",
        "  img = base64.decodebytes(r.json()[str(i)].encode('ascii'))\n",
        "  img = Image.open(BytesIO(img)).convert('RGBA')\n",
        "  imgs.append(img)\n",
        "\n",
        "imgs[1]"
      ],
      "metadata": {
        "id": "EEe5-KhLz8qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#collapse\n",
        "%%writefile ./ebsapp/application.py\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from shutil import move\n",
        "from pandas import read_csv\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from annoy import AnnoyIndex\n",
        "from scipy import spatial\n",
        "import pickle\n",
        "import time\n",
        "from PIL import Image\n",
        "import tarfile\n",
        "import io\n",
        "import base64\n",
        "from flask import Flask, request, jsonify, send_file\n",
        "from flask import redirect, url_for, flash, render_template\n",
        "\n",
        "# path = Path(__file__)\n",
        "# _PPATH = str(path.parents[1])+'/'\n",
        "_PPATH = os.path.join(os.getcwd(), 'mytemp')\n",
        "\n",
        "def load_img(path):\n",
        "  img = tf.io.read_file(path)\n",
        "  img = tf.io.decode_jpeg(img, channels=3)\n",
        "  img = tf.image.resize_with_pad(img, 224, 224)\n",
        "  img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "  return img\n",
        "\n",
        "module_handle = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4\"\n",
        "module = hub.load(module_handle)\n",
        "\n",
        "def allowed_file(filename):\n",
        "    return '.' in filename and \\\n",
        "           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
        "\n",
        "topK = 5\n",
        "threshold = 0.3\n",
        "UPLOAD_FOLDER = _PPATH\n",
        "ALLOWED_EXTENSIONS = set(['zip'])\n",
        "\n",
        "application = Flask(__name__)\n",
        "\n",
        "@application.route('/')\n",
        "def hello_world():\n",
        "    return \"Hello world!\"\n",
        "\n",
        "@application.route('/original_images', methods=['POST'])\n",
        "def upload_zip1():\n",
        "  os.makedirs(_PPATH, exist_ok=True)\n",
        "  shutil.rmtree(_PPATH)\n",
        "  os.makedirs(_PPATH, exist_ok=True)\n",
        "  os.chdir(_PPATH)\n",
        "  file = request.files['file']\n",
        "  if file and allowed_file(file.filename):\n",
        "      file.save(os.path.join(UPLOAD_FOLDER, 'zip1.zip'))\n",
        "\n",
        "  zip1_path = os.path.join(_PPATH, 'zip1.zip')\n",
        "  zip1_ipath = os.path.join(_PPATH, 'zip1')\n",
        "  os.makedirs(zip1_ipath, exist_ok=True)\n",
        "  with zipfile.ZipFile(zip1_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.join(_PPATH, 'zip1'))\n",
        "\n",
        "  img_paths = []\n",
        "  for path in Path(zip1_ipath).rglob('*.jpg'):\n",
        "    img_paths.append(path)\n",
        "\n",
        "  imgvec_path = os.path.join(_PPATH, 'vecs1')\n",
        "  Path(imgvec_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  for filename in tqdm(img_paths):\n",
        "    outfile_name = os.path.basename(filename).split('.')[0] + \".npz\"\n",
        "    out_path_file = os.path.join(imgvec_path, outfile_name)\n",
        "    if not os.path.exists(out_path_file):\n",
        "      img = load_img(str(filename))\n",
        "      features = module(img)\n",
        "      feature_set = np.squeeze(features)\n",
        "      print(features.shape)\n",
        "      np.savetxt(out_path_file, feature_set, delimiter=',')\n",
        "\n",
        "  # Defining data structures as empty dict\n",
        "  file_index_to_file_name = {}\n",
        "  file_index_to_file_vector = {}\n",
        "\n",
        "  # Configuring annoy parameters\n",
        "  dims = 2048\n",
        "  n_nearest_neighbors = 20\n",
        "  trees = 10000\n",
        "\n",
        "  # Reads all file names which stores feature vectors\n",
        "  allfiles = glob.glob(os.path.join(_PPATH, 'vecs1', '*.npz'))\n",
        "\n",
        "  t = AnnoyIndex(dims, metric='angular')\n",
        "\n",
        "  for findex, fname in tqdm(enumerate(allfiles)):\n",
        "    file_vector = np.loadtxt(fname)\n",
        "    file_name = os.path.basename(fname).split('.')[0]\n",
        "    file_index_to_file_name[findex] = file_name\n",
        "    file_index_to_file_vector[findex] = file_vector\n",
        "    t.add_item(findex, file_vector)\n",
        "\n",
        "  t.build(trees)\n",
        "\n",
        "  file_path = os.path.join(_PPATH,'models/indices/')\n",
        "  Path(file_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  t.save(file_path+'indexer.ann')\n",
        "  pickle.dump(file_index_to_file_name, open(file_path+\"file_index_to_file_name.p\", \"wb\"))\n",
        "  pickle.dump(file_index_to_file_vector, open(file_path+\"file_index_to_file_vector.p\", \"wb\"))\n",
        "\n",
        "  return 'File processed on the server status OK!'\n",
        "\n",
        "@application.route('/test_images', methods=['POST'])\n",
        "def upload_zip2():\n",
        "  os.chdir(_PPATH)\n",
        "  file = request.files['file']\n",
        "  if file and allowed_file(file.filename):\n",
        "      file.save(os.path.join(UPLOAD_FOLDER, 'zip2.zip'))\n",
        "\n",
        "  zip2_path = os.path.join(_PPATH, 'zip2.zip')\n",
        "  zip2_ipath = os.path.join(_PPATH, 'zip2')\n",
        "  os.makedirs(zip2_ipath, exist_ok=True)\n",
        "  with zipfile.ZipFile(zip2_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(os.path.join(_PPATH, 'zip2'))\n",
        "\n",
        "  query_files = []\n",
        "  for path in Path(zip2_ipath).rglob('*.jpg'):\n",
        "    query_files.append(path)\n",
        "\n",
        "  dims = 2048\n",
        "  indexer = AnnoyIndex(dims, 'angular')\n",
        "  indexer.load(os.path.join(_PPATH,'models/indices/indexer.ann'))\n",
        "  file_index_to_file_name = pickle.load(open(os.path.join(_PPATH,'models/indices/file_index_to_file_name.p'), 'rb'))\n",
        "\n",
        "  results = pd.DataFrame(columns=['qid','fname','dist'])\n",
        "\n",
        "  for q in query_files:\n",
        "    temp_vec = np.squeeze(module(load_img(str(q))))\n",
        "    nns = indexer.get_nns_by_vector(temp_vec, n=topK, include_distances=True)\n",
        "    col1 = [q.stem]*topK\n",
        "    col2 = [file_index_to_file_name[x] for x in nns[0]]\n",
        "    col3 = nns[1]\n",
        "    results = results.append(pd.DataFrame({'qid':col1,'fname':col2,'dist':col3}))\n",
        "    results = results[results.dist<=threshold]\n",
        "\n",
        "  results = results.reset_index(drop=True).T.to_json()\n",
        "  return results\n",
        "\n",
        " # run the app.\n",
        "if __name__ == \"__main__\":\n",
        "    # Setting debug to True enables debug output. This line should be\n",
        "    # removed before deploying a production app.\n",
        "    application.debug = True\n",
        "    application.run()"
      ],
      "metadata": {
        "id": "CL7u0wZuz_eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#collapse\n",
        "%%writefile ./ebsapp/requirements.txt\n",
        "annoy==1.16.3\n",
        "Pillow==2.2.2\n",
        "click==7.1.2\n",
        "Flask==1.1.2\n",
        "itsdangerous==1.1.0\n",
        "Jinja2==2.11.2\n",
        "MarkupSafe==1.1.1\n",
        "Werkzeug==1.0.1\n",
        "numpy==1.18.5\n",
        "pandas==1.0.5\n",
        "pathlib==1.0.1\n",
        "pip-tools==4.5.1\n",
        "requests==2.23.0\n",
        "scipy==1.4.1\n",
        "tensorflow==2.0.0b1\n",
        "tensorflow-hub==0.8.0\n",
        "tqdm==4.41.1\n",
        "urllib3==1.24.3\n",
        "zipfile36==0.1.3"
      ],
      "metadata": {
        "id": "tp4w-O870JuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#collapse\n",
        "%%writefile ./ebsapp/.ebextensions/01_packages.config\n",
        "packages:\n",
        "  yum:\n",
        "    gcc-c++: []\n",
        "    unixODBC-devel: []\n",
        "files:\n",
        "  \"/etc/httpd/conf.d/wsgi_custom.conf\":\n",
        "    mode: \"000644\"\n",
        "    owner: root\n",
        "    group: root\n",
        "    content: |\n",
        "      WSGIApplicationGroup %{GLOBAL}"
      ],
      "metadata": {
        "id": "lAQGb6ub0NPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#collapse\n",
        "!pip install aws.sam.cli\n",
        "!sam init\n",
        "\n",
        "%cd my-app\n",
        "\n",
        "!git config --global user.email \"<email>\"\n",
        "!git config --global user.name  \"sparsh-ai\"\n",
        "!git init\n",
        "!git status\n",
        "!git add .\n",
        "!git commit -m 'commit'\n",
        "\n",
        "!pip install awscli\n",
        "!aws configure\n",
        "\n",
        "!sam build && sam deploy\n",
        "!pip install flask-lambda-python36\n",
        "\n",
        "!aws ec2 create-key-pair --key-name MyKeyPair --query 'KeyMaterial' --output text > MyKeyPair.pem\n",
        "!chmod 400 MyKeyPair.pem\n",
        "!aws ec2 describe-instances --filters \"Name=instance-type,Values=t2.micro\" --query \"Reservations[].Instances[].InstanceId\"\n",
        "!ssh -i MyKeyPair.pem ec2-user@ec2-50-xx-xx-xxx.compute-1.amazonaws.com\n",
        "\n",
        "!git clone https://github.com/aws/aws-elastic-beanstalk-cli-setup.git\n",
        "!build-essential zlib1g-dev libssl-dev libncurses-dev libffi-dev libsqlite3-dev libreadline-dev libbz2-dev\n",
        "\n",
        "!pip install awscli\n",
        "!pip install awsebcli\n",
        "!aws configure\n",
        "\n",
        "!mkdir eb-flask\n",
        "%cd eb-flask\n",
        "\n",
        "# python --version\n",
        "# pip install awsebcli --upgrade --user\n",
        "# eb --version\n",
        "# mkdir eb-flask\n",
        "# cd eb-flask\n",
        "# pip install virtualenv\n",
        "!virtualenv virt\n",
        "!source virt/bin/activate\n",
        "!pip install flask\n",
        "!pip freeze\n",
        "!pip freeze > requirements.txt\n",
        "!python application.py\n",
        "# eb init -p python-3.6 my-app --region us-east-1\n",
        "# pip install zip-files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU8Figiz0OJd",
        "outputId": "15e72ac8-be9b-4fa6-9d0b-9c9c62f78a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/.git/\n",
            "On branch master\n",
            "\n",
            "No commits yet\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31m.config/\u001b[m\n",
            "\t\u001b[31m2711357163ada02c14c.webp\u001b[m\n",
            "\t\u001b[31mFashion_data/\u001b[m\n",
            "\t\u001b[31mdrive/\u001b[m\n",
            "\t\u001b[31mfashion-product-images-small.zip\u001b[m\n",
            "\t\u001b[31mkaggle.json\u001b[m\n",
            "\t\u001b[31mmyntradataset/\u001b[m\n",
            "\t\u001b[31msample_data/\u001b[m\n",
            "\t\u001b[31mstyles.csv\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n",
            "warning: adding embedded git repository: Fashion_data/aws-elastic-beanstalk-cli-setup\n",
            "\u001b[33mhint: You've added another git repository inside your current repository.\u001b[m\n",
            "\u001b[33mhint: Clones of the outer repository will not contain the contents of\u001b[m\n",
            "\u001b[33mhint: the embedded repository and will not know how to obtain it.\u001b[m\n",
            "\u001b[33mhint: If you meant to add a submodule, use:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit submodule add <url> Fashion_data/aws-elastic-beanstalk-cli-setup\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: If you added this path by mistake, you can remove it from the\u001b[m\n",
            "\u001b[33mhint: index with:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit rm --cached Fashion_data/aws-elastic-beanstalk-cli-setup\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: See \"git help submodule\" for more information.\u001b[m\n",
            "error: open(\"drive/MyDrive/Apresentação sem título.gslides\"): Operation not supported\n",
            "error: unable to index file 'drive/MyDrive/Apresentação sem título.gslides'\n",
            "fatal: adding files failed\n",
            "On branch master\n",
            "\n",
            "Initial commit\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31m.config/\u001b[m\n",
            "\t\u001b[31m2711357163ada02c14c.webp\u001b[m\n",
            "\t\u001b[31mFashion_data/\u001b[m\n",
            "\t\u001b[31mdrive/\u001b[m\n",
            "\t\u001b[31mfashion-product-images-small.zip\u001b[m\n",
            "\t\u001b[31mkaggle.json\u001b[m\n",
            "\t\u001b[31mmyntradataset/\u001b[m\n",
            "\t\u001b[31msample_data/\u001b[m\n",
            "\t\u001b[31mstyles.csv\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n",
            "Requirement already satisfied: awscli in /usr/local/lib/python3.11/dist-packages (1.37.24)\n",
            "Collecting botocore==1.36.24 (from awscli)\n",
            "  Using cached botocore-1.36.24-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: docutils<0.17,>=0.10 in /usr/local/lib/python3.11/dist-packages (from awscli) (0.16)\n",
            "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from awscli) (0.11.2)\n",
            "Requirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.11/dist-packages (from awscli) (6.0.2)\n",
            "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from awscli) (0.4.6)\n",
            "Requirement already satisfied: rsa<4.8,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from awscli) (4.7.2)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from botocore==1.36.24->awscli) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore==1.36.24->awscli) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore==1.36.24->awscli) (1.26.20)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.36.24->awscli) (1.17.0)\n",
            "Using cached botocore-1.36.24-py3-none-any.whl (13.4 MB)\n",
            "Installing collected packages: botocore\n",
            "  Attempting uninstall: botocore\n",
            "    Found existing installation: botocore 1.35.99\n",
            "    Uninstalling botocore-1.35.99:\n",
            "      Successfully uninstalled botocore-1.35.99\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "awsebcli 3.21.0 requires botocore<1.36.0,>=1.35.0, but you have botocore 1.36.24 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed botocore-1.36.24\n",
            "AWS Access Key ID [None]: "
          ]
        }
      ]
    }
  ]
}